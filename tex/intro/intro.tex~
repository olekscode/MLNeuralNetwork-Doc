In this [thesis] I will describe my implementation of artificial neural networks in Pharo. 

\section{What is Pharo?}
Pharo is a modern, open-source, dynamically typed language supporting live coding and inspired by Smalltalk.

The important principle behind Pharo is that it doesnâ€™t just copy the past, but reinvents the essence behind Smalltalk.

Pharo is not read-only, it integrates the changes made by community, daily. [By now it has more than a hundred contributors] \cite{PBE2}.

\section{Installing the Library}
To use my library you must first install Pharo. It is available for all major operating systems

\subsection{Getting Pharo}

\subsection{Installing the Dependencies}
Here is the complete list of dependencies:
\begin{itemize}
  \item \textbf{PolyMath} - a library for numerical methods. It provides MATLAB-like vectors and matrices. It is simmilar to numpy library in Python.
  \item \textbf{Roassal} - a library for agile visualizations. The only part dependent on Roassal is MLVisualizer class. All data and metrics are provided in a type that is supported either by Pharo base, or by PolyMath. So if you wish to use something other visualization tool - you are free to do that. However, all examples in this [thesis] will be visualised with MLVisualizer which uses Roassal.
  \item \textbf{IdxReader} - a package for reading the data in idx format, designed by [Guilermo Polito]. The MLDataReader class uses it to read the MNIST dataset of handwritten digits. If you don't want to use this dataset - you can ignore this dependency. Everything else will work just fine.
\end{itemize}

\section{Examples of Usage}
To create an instance of MLNeuralNetwork class you must provide an inforamtion about the network architecture, defined by a simple one-dimensional array of integers $\#(s_{1} s_{2} ... s_{n})$. The size of an array $n$ represents the number of layers in the network, and each number $s_{i}$ is the number of neurons in that layer.

\begin{lstlisting}
neuralNet := MLNeuralNetwork new initialize: #(784 500 10).
\end{lstlisting}

This code will create a neural network with 784 input units, one hidden layer with 500 neurons, and an output layer with 10 neurons (this network can be used to classify the input data into 10 classes).
