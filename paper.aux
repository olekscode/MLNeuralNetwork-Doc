\relax 
\citation{PBE2}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Related work}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}What is Pharo?}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Installing the library}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}Getting Pharo}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.2}Installing the Dependencies}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Example of usage}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {1.5}How to contribute?}{3}}
\citation{MacKay-2003}
\citation{Mitchell-1997}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Machine learning with neural networks}{4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}What is machine learning?}{4}}
\@writefile{toc}{\contentsline {paragraph}{Definition}{4}}
\citation{Russell-Norvig-2010}
\citation{Raina-et-al-2009}
\citation{Haykin-2005}
\citation{Hastie-et-al-2013}
\citation{MacKay-2003}
\citation{Goodfellow-et-al-2016}
\@writefile{toc}{\contentsline {paragraph}{Machine learning problems}{5}}
\@writefile{toc}{\contentsline {paragraph}{Task of supervised learning}{5}}
\@writefile{toc}{\contentsline {paragraph}{Task of unsupervised learning}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Neural networks}{5}}
\@writefile{toc}{\contentsline {paragraph}{Definition}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Model of a neuron}{6}}
\@writefile{toc}{\contentsline {paragraph}{Biological neurons}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces A schematic of biological neuron}}{7}}
\newlabel{fig:bioneuron}{{2.1}{7}}
\@writefile{toc}{\contentsline {paragraph}{Artificial neurons}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Model of artifitial neuron}}{7}}
\newlabel{fig:artifneuron}{{2.2}{7}}
\citation{Hastie-et-al-2013}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Structure and representation}{8}}
\@writefile{toc}{\contentsline {paragraph}{Graphical representation}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces (1) Recurrent neural network represented by directed graph. (2) 3-layered feedforward neural network represented by 3-partide directed graph. (3) 3-layered fully-connected feedforward neural network represented by a complete 3-partide directed graph}}{8}}
\newlabel{fig:graphs}{{2.3}{8}}
\@writefile{toc}{\contentsline {paragraph}{Network topologies}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Feedforward artificial neural network with one hidden layer. Number of neurons in each layer: 3 (2-dimentional input + bias unit) in the input layer, 4 in the hidden layer, 1 in the output layer (1-demensional output)}}{9}}
\newlabel{fig:net}{{2.4}{9}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Single-layer perceptron}{10}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Object-oriented design of a single-layer perceptron}}{10}}
\newlabel{fig:slp1}{{3.1}{10}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}What is a perceptron?}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Restrictions of perceptrons}{11}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Design issues}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}How to represent weights?}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Activation functions}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Implementing activation functions as methods of specific subclasses on Neuron}}{12}}
\newlabel{fig:activation1}{{3.2}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Implementing activation functions as separate classes}}{13}}
\newlabel{fig:activation2}{{3.3}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Shared or separate activation and learning rate?}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces A convolutional neural network with four hidden layers}}{14}}
\newlabel{fig:conv}{{3.4}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.4}Data shuffling}{14}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Implementation}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Object-oriented design of a single-layer perceptron}}{15}}
\newlabel{fig:slp2}{{3.5}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Neuron class}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}SLPerceptron class}{16}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Testing}{17}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Multi-layer neural network}{19}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Implementing activation functions as methods of specific subclasses on Neuron}}{19}}
\newlabel{fig:mlnn}{{4.1}{19}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Implementing activation functions as methods of specific subclasses on Neuron}}{20}}
\newlabel{fig:backprop_seq}{{4.2}{20}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Why not "multi-layer perceptron"?}{20}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Design issues}{20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Weight initialization}{20}}
\citation{Saxe-et-al-TODO}
\citation{Trushevskyi-2014}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Implementation}{21}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Testing}{21}}
\bibstyle{plain}
\bibdata{paper}
\bibcite{PBE2}{1}
\bibcite{Goodfellow-et-al-2016}{2}
\bibcite{Hastie-et-al-2013}{3}
\bibcite{Haykin-2005}{4}
\bibcite{MacKay-2003}{5}
\bibcite{Mitchell-1997}{6}
\bibcite{Raina-et-al-2009}{7}
\bibcite{Russell-Norvig-2010}{8}
\bibcite{Saxe-et-al-TODO}{9}
\bibcite{Trushevskyi-2014}{10}
